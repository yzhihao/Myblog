---
layout: post
title: Gengerative Adversarial Networks
desc: 我的博客
keywords: 'blog,Machine Learning,AI'
date: 2017-3-14T00:00:00.000Z
categories:
  - Machine Learning
tags:
  - Machine Learning
  - AI
icon: fa-book
---


## 目录
**欢迎在文章下方评论，建议用电脑看**

* 目录
{:toc}



# 生成对抗网络

## 概述

这些网络的要点是：有两个模型，一个是生成模型（generative model），一个是判别模型(discriminative model)。判别模型的任务是判断给定的图像看起来是自然的还是人为伪造的（图像来源于数据集）。生成模型的任务是生成看起来自然真实的、和原始数据相似的图像。这可以看做一种零和或两个玩家的纸牌游戏。本文采用的类比是生成模型像“一个造假团伙，试图生产和使用假币”，而判别模型像“检测假币的警察”。生成器（generator）试图欺骗判别器（discriminator），判别器则努力不被生成器欺骗。模型经过交替优化训练，两种模型都能得到提升，直到到达一个“假冒产品和真实产品无法区分”的点。

## 训练

在训练的过程中**固定一方，更新另一方的网络权重，交替迭代，在这个过程中，双方都极力优化自己的网络，从而形成竞争对抗，直到双方达到一个动态的平衡（纳什均衡）**，此时生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%，约等于乱猜。

算法流程：

![](http://img.blog.csdn.net/20160915122301396)



### 最优生成器:

直观来说，之前在生成器中展示的代码向量将会代表抽象的东西。例如，如果代码向量有 100 维度，可能会由一维自动代表了「面部年龄」或「性别」。

为什么生成器会学习到这种表示呢？因为知道了人们的年龄和性别会帮助你画出更适合他们的人脸图片。

### 最优辨别器:

给定一张图片，辨别器必须找到正确区分真实和生成的人脸的部分。

直观上说，当辨别器中的一些隐藏神经元看到比如眼睛，嘴巴，头发等物体时，他们就会被激活。这些特征对之后的其他任务比如分类是很有用的。

### 训练辨别器:

给它一张训练集中的图片和一张生成器生成的图片，如果得到的是生成图片辨别器应该输出 0，如果是真实的图片应该输出 1。

从技术性的角度：交叉熵的损失可以由最优控制器弥补，小菜一碟！

### 训练生成器:

生成器必须努力让辨别器在得到它生成的图片后输出 1。

现在，这有一个有趣的部分。

假设生成器生成了一张图片，辨别器认为这张图片有 0.4 的概率是真实图片。生成器如何调整它生成的图片来增加这个概率，比如说增加到 0.41？

答案就是：

为训练生成器，辨别器不得不告诉生成器如何调整从而使它生成的图片变得更加真实。

生成器必须向辨别器寻求建议！

直观来说，辨别器告诉生成器每个像素应调整多少来使整幅图像更真实一点点。

技术上来说，通过反向传播辨别器输出的梯度来调整生成图片。以这种方式训练生成器，你将会得到与图片形状一样的梯度向量。

如果你把这些梯度加到生成的图片上，在辨别器看来，图片就会变得更真实一点。

但是我们不仅仅把梯度加到图片上。

相反，我们进一步反向传播这些图片梯度成为组成生成器的权重，这样一来，生成器就学习到如何生成这幅新图片。


下面是两网络在最优高级状态学习时对话的直观感受:

    G:我有一张人脸图片，它跟你以前见过的人脸图片相比足够真实吗？

    D:这张图片真的很真实 (对真实图片，辨别器会产生 0.5 的概率) 但是这张图片是不是真的，我完全没有头绪。因为显而易见的是，你在生成真实图片上做的太好了。

    G:这是我生成的一张图片。我知道这已经是真实的了但是我想要更多，我应该如何调整来使它变的更真实？

    D:让我想一下 (实际上大脑里在做反向传播) 我认为你的图片已经有了我认为需要有的部分。我看起来非常真实。显然你的图片包含眼睛，嘴巴，耳朵，头发，图片里是一张年轻男孩的脸。我不认为我有建议的东西。但是如果你想的话，可以把年轻男孩的胡须去掉。

    (技术上来说，我认为你第 0 个像素灰度值增加 6，第 1 个像素灰度值减少 7，...，第 4095 个像素灰度值增加 2。)

    G:收到 (反向传播那些梯度给所有的权重)

经过一段时间的训练，它们会变得越来越聪明，直到他们达到非常高级的最优状态。

它们在无人监督的情况下也都能理解胡须，眼睛，嘴巴，头发，年轻的脸庞。

你已经达到了一种平衡。

如果你持续不断的教导生成器如何使照片更加真实，就会很可能过拟合，就像辨别器会认为一个小男孩根本就不应该有胡子一样。辨别器会产生这样的想法，但是这可能不对。就像你不应太过依赖老师的意见一样。继续训练也不会得到任何东西。

##  GAN模型优化：

理解了上面的之后，下面就是直接上数学式子了：

GAN模型没有损失函数，优化过程是一个“二元极小极大博弈（minimax two-player game）”问题:

<img src="{{ site.img_path }}/Machine Learning/gan_loss.png" alt="header1" style="height:auto!important;width:auto%;max-width:1020px;"/>

这是关于判别网络D和生成网络G的**价值函数（Value Function），训练网络D使得最大概率地分对训练样本的标签（最大化log D(x)），训练网络G最小化log(1 – D(G(z)))，即最大化D的损失。**训练过程中固定一方，更新另一个网络的参数，交替迭代，使得对方的错误最大化，最终，G 能估测出样本数据的分布。生成模型G隐式地定义了一个概率分布Pg，我们希望Pg 收敛到数据真实分布Pdata。论文证明了这个极小化极大博弈当且仅当Pg = Pdata时存在最优解，即达到纳什均衡，此时生成模型G恢复了训练数据的分布，判别模型D的准确率等于50%。

>注意这里在介绍原始基本的gan，其实现在，这个价值函数已经发生很大的变化，如果从原理来说的话，就是用Wasserstein距离来量度真实分布和生成分布之间的差距，具体看[这篇博文]()

## DCGAN

[论文地址：[1511.06434] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf)



DCGAN把上述的G和D用了两个卷积神经网络（CNN）。但不是直接换就可以了，DCGAN对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度，这些改变有：

* 取消所有pooling层。G网络中使用转置卷积（transposed convolutional layer）进行上采样，D网络中用加入stride的卷积代替pooling。
* 在D和G中均使用batch normalization
* 去掉FC层，使网络变为全卷积网络
* G网络中使用ReLU作为激活函数，最后一层使用tanh
* D网络中使用LeakyReLU作为激活函数

DCGAN中的G网络示意：

<img src="{{ site.img_path }}/Machine Learning/gan_model_dc.png" alt="header1" style="height:auto!important;width:auto%;max-width:1020px;"/>

可以看出输入的是高斯分布的数据，最终生成图片，相等于卷积网络的逆过程。






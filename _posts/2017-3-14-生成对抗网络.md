---
layout: post
title: Gengerative Adversarial Networks
desc: 我的博客
keywords: 'blog,Machine Learning,AI'
date: 2017-3-14T00:00:00.000Z
categories:
  - Machine Learning
tags:
  - Machine Learning
  - AI
icon: fa-book
---


## 目录
**欢迎在文章下方评论，建议用电脑看**

* 目录
{:toc}



# 生成对抗网络

## 概述
* 这些网络的要点是：有两个模型，一个是生成模型（generative model），一个是判别模型(discriminative model)。判别模型的任务是判断给定的图像看起来是自然的还是人为伪造的（图像来源于数据集）。生成模型的任务是生成看起来自然真实的、和原始数据相似的图像。这可以看做一种零和或两个玩家的纸牌游戏。本文采用的类比是生成模型像“一个造假团伙，试图生产和使用假币”，而判别模型像“检测假币的警察”。生成器（generator）试图欺骗判别器（discriminator），判别器则努力不被生成器欺骗。模型经过交替优化训练，两种模型都能得到提升，直到到达一个“假冒产品和真实产品无法区分”的点。

## 训练
* 在训练的过程中固定一方，更新另一方的网络权重，交替迭代，在这个过程中，双方都极力优化自己的网络，从而形成竞争对抗，直到双方达到一个动态的平衡（纳什均衡），此时生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%，约等于乱猜。

算法流程：

![](http://img.blog.csdn.net/20160915122301396)



### 最优生成器

直观来说，之前在生成器中展示的代码向量将会代表抽象的东西。例如，如果代码向量有 100 维度，可能会由一维自动代表了「面部年龄」或「性别」。

为什么生成器会学习到这种表示呢？因为知道了人们的年龄和性别会帮助你画出更适合他们的人脸图片。

### 最优辨别器

给定一张图片，辨别器必须找到正确区分真实和生成的人脸的部分。

直观上说，当辨别器中的一些隐藏神经元看到比如眼睛，嘴巴，头发等物体时，他们就会被激活。这些特征对之后的其他任务比如分类是很有用的。

### 训练辨别器

给它一张训练集中的图片和一张生成器生成的图片，如果得到的是生成图片辨别器应该输出 0，如果是真实的图片应该输出 1。

从技术性的角度：交叉熵的损失可以由最优控制器弥补，小菜一碟！

### 训练生成器

生成器必须努力让辨别器在得到它生成的图片后输出 1。

现在，这有一个有趣的部分。

假设生成器生成了一张图片，辨别器认为这张图片有 0.4 的概率是真实图片。生成器如何调整它生成的图片来增加这个概率，比如说增加到 0.41？

答案就是：

为训练生成器，辨别器不得不告诉生成器如何调整从而使它生成的图片变得更加真实。

生成器必须向辨别器寻求建议！

直观来说，辨别器告诉生成器每个像素应调整多少来使整幅图像更真实一点点。

技术上来说，通过反向传播辨别器输出的梯度来调整生成图片。以这种方式训练生成器，你将会得到与图片形状一样的梯度向量。

如果你把这些梯度加到生成的图片上，在辨别器看来，图片就会变得更真实一点。

但是我们不仅仅把梯度加到图片上。

相反，我们进一步反向传播这些图片梯度成为组成生成器的权重，这样一来，生成器就学习到如何生成这幅新图片。


下面是两网络在最优高级状态学习时对话的直观感受:

    G:我有一张人脸图片，它跟你以前见过的人脸图片相比足够真实吗？

    D:这张图片真的很真实 (对真实图片，辨别器会产生 0.5 的概率) 但是这张图片是不是真的，我完全没有头绪。因为显而易见的是，你在生成真实图片上做的太好了。

    G:这是我生成的一张图片。我知道这已经是真实的了但是我想要更多，我应该如何调整来使它变的更真实？

    D:让我想一下 (实际上大脑里在做反向传播) 我认为你的图片已经有了我认为需要有的部分。我看起来非常真实。显然你的图片包含眼睛，嘴巴，耳朵，头发，图片里是一张年轻男孩的脸。我不认为我有建议的东西。但是如果你想的话，可以把年轻男孩的胡须去掉。

    (技术上来说，我认为你第 0 个像素灰度值增加 6，第 1 个像素灰度值减少 7，...，第 4095 个像素灰度值增加 2。)

    G:收到 (反向传播那些梯度给所有的权重)

经过一段时间的训练，它们会变得越来越聪明，直到他们达到非常高级的最优状态。

它们在无人监督的情况下也都能理解胡须，眼睛，嘴巴，头发，年轻的脸庞。

你已经达到了一种平衡。

如果你持续不断的教导生成器如何使照片更加真实，就会很可能过拟合，就像辨别器会认为一个小男孩根本就不应该有胡子一样。辨别器会产生这样的想法，但是这可能不对。就像你不应太过依赖老师的意见一样。继续训练也不会得到任何东西。

##  GAN模型优化：

理解了上面的之后，下面就是直接上数学式子了：

GAN模型没有损失函数，优化过程是一个“二元极小极大博弈（minimax two-player game）”问题: ![](http://img.blog.csdn.net/20160915111717898)

这是关于判别网络D和生成网络G的价值函数（Value Function），训练网络D使得最大概率地分对训练样本的标签（最大化log D(x)），训练网络G最小化log(1 – D(G(z)))，即最大化D的损失。训练过程中固定一方，更新另一个网络的参数，交替迭代，使得对方的错误最大化，最终，G 能估测出样本数据的分布。生成模型G隐式地定义了一个概率分布Pg，我们希望Pg 收敛到数据真实分布Pdata。论文证明了这个极小化极大博弈当且仅当Pg = Pdata时存在最优解，即达到纳什均衡，此时生成模型G恢复了训练数据的分布，判别模型D的准确率等于50%。

## DCGAN

[论文地址：[1511.06434] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf)



CGAN的原理和GAN是一样的，这里就不在赘述。它只是把上述的G和D换成了两个卷积神经网络（CNN）。但不是直接换就可以了，DCGAN对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度，这些改变有：

* 取消所有pooling层。G网络中使用转置卷积（transposed convolutional layer）进行上采样，D网络中用加入stride的卷积代替pooling。
* 在D和G中均使用batch normalization
* 去掉FC层，使网络变为全卷积网络
* G网络中使用ReLU作为激活函数，最后一层使用tanh
* D网络中使用LeakyReLU作为激活函数

DCGAN中的G网络示意：

![](https://pic2.zhimg.com/v2-1c06594f38b896e8d15154592bae0309_b.jpg)

可以看出输入的是高斯分布的数据，最终生成图片，相等于卷积网络的逆过程。

## GAN目前存在的主要问题：

### 解决不收敛（non-convergence）的问题。

目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。

### 难以训练：崩溃问题（collapse problem）

GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。【Improved Techniques for Training GANs】

### 无需预先建模，模型过于自由不可控。

与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。

>生成器在生成数据和人脸时效果很好，但使用CIFAR-10数据集时，生成的图像就十分模糊。

### 利用对抗网络拉普拉斯金字塔的深度生成分辨率高的图像模型
* 为了解决这个问题,有了这篇论文，这篇论文的主要贡献一种网络架构，它制作的高质量合成图像由人类检查时，40%的时候与真实图像难以区分。
* 生成低分辨率的图像很简单。根据低分辨率图像生成分辨率高一点的图像也不算难。
* 论文作者提出一套convnet模型，金字塔的每一层都包含与之关联的convnet。这和传统GAN结构的变化是，传统GAN只能由一个生成器CNN生产整个图像，而新的模型由一系列的CNN通过渐渐增加分辨率（即经过金字塔）连续生成图像，把图像由粗糙变精致。每一层都有独自的CNN，由两个部分训练。一个是低分辨率图像，另一个是噪声矢量（这是传统GAN的唯一输入）。这就是多种输入的CGAN的原理。输出的图像会被作为样本再次输入给金字塔的下一层。这种方法很有效，因为每一层的生成器都能利用不同的分辨率信息，以在连续的层里合成更精细的图像。

## Wesserstein GAN
做到了以下爆炸性的几点：
 1. 彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度
 2. 基本解决了collapse mode的问题，确保了生成样本的多样性
 3. 训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高（如题图所示）
 3. 以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到

### 改进原始算法

1. 判别器最后一层去掉sigmoid
2. 生成器和判别器的loss不取log
3. 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c
4. 不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行

Wesserstein GAN的算法如下：
![](https://pic1.zhimg.com/v2-6be6e2ef3d15c4b10c2a943e9bf4db70_b.jpg)

## 原始GAN形式的问题

### 第一种原始GAN形式的问题

一句话概括：判别器越好，生成器梯度消失越严重

下图就是直观认识：
![](https://pic4.zhimg.com/v2-8715a60c1a8993953f125e03938125d7_b.jpg)

WGAN前作Figure 2。先分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第一种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，生成器的梯度均迅速衰减。注意y轴是对数坐标轴。


下面就从两个角度去解决阐述这个问题

#### 第一个角度进行论证

在（近似）最优判别器下，最小化生成器的loss等价于最小化P_r与P_g之间的JS散度，而由于P_r与P_g几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数\log 2，最终导致生成器的梯度（近似）为0，梯度消失。下面来简单解释一下：

首先损失函数如下：
![](http://zhihu.com/equation?tex=%5Cmathbb%7BE%7D_%7Bx%5Csim+P_r%7D%5B%5Clog+D%28x%29%5D+%2B+%5Cmathbb%7BE%7D_%7Bx%5Csim+P_g%7D%5B%5Clog%281-D%28x%29%29%5D)
最小化这个损失函数，它刚好是判别器损失函数的反。代入最优判别器即上式，再进行简单的变换可以得到：
![](http://zhihu.com/equation?tex=%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_r%7D+%5Clog+%5Cfrac%7BP_r%28x%29%7D%7B%5Cfrac%7B1%7D%7B2%7D%5BP_r%28x%29+%2B+P_g%28x%29%5D%7D+%2B+%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5Clog+%5Cfrac%7BP_g%28x%29%7D%7B%5Cfrac%7B1%7D%7B2%7D%5BP_r%28x%29+%2B+P_g%28x%29%5D%7D+-+2%5Clog+2)
变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度：

![](http://zhihu.com/equation?tex=KL%28P_1%7C%7CP_2%29+%3D+%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_1%7D+%5Clog+%5Cfrac%7BP_1%7D%7BP_2%7D)
![](http://zhihu.com/equation?tex=JS%28P_1+%7C%7C+P_2%29+%3D+%5Cfrac%7B1%7D%7B2%7DKL%28P_1%7C%7C%5Cfrac%7BP_1+%2B+P_2%7D%7B2%7D%29+%2B+%5Cfrac%7B1%7D%7B2%7DKL%28P_2%7C%7C%5Cfrac%7BP_1+%2B+P_2%7D%7B2%7D%29)

于是公式5就可以继续写成

![](http://zhihu.com/equation?tex=2JS%28P_r+%7C%7C+P_g%29+-+2%5Clog+2)

根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在**最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化P_r和P_g之间的JS散度。**

问题就出在这个JS散度上。我们会希望如果两个分布之间越接近它们的JS散度越小，我们通过优化JS散度就能将P_g“拉向”P_r，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），JS散度就固定是常数log 2，而这对于梯度下降方法意味着——梯度为0！

而且：**P_r与P_g不重叠或重叠部分可忽略的可能性非常大** 下面解释专业解释：

当P_r与P_g的支撑集（support）是高维空间中的低维流形（manifold）时，P_r与P_g重叠部分测度（measure）为0的概率为1。

不用被奇怪的术语吓得关掉页面，虽然论文给出的是严格的数学表述，但是直观上其实很容易理解。首先简单介绍一下这几个概念：

支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是(0, +\infty)，一个概率分布的支撑集就是所有概率密度非零部分的集合。
流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。
测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。
回过头来看第一句话，“当P_r与P_g的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。

“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以P_g几乎不可能与P_r有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比P_r和P_g的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。


关于Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）[详看](https://zhuanlan.zhihu.com/p/25071913)

#### 第二个角度进行论证
背后的思想也可以直观地解释：

* 首先，与之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。
* 由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。
* 最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。


### 第二种原始GAN形式的问题

最小化第二种生成器loss函数，会**等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。**

如前文所说，Ian Goodfellow提出的“- log D trick”是把生成器loss改成

![](http://zhihu.com/equation?tex=%5Cmathbb%7BE%7D_%7Bx%5Csim+P_g%7D%5B-+%5Clog+D%28x%29%5D)（公式3） 

上文推导已经得到在最优判别器D^*下

![](http://zhihu.com/equation?tex=%5Cmathbb%7BE%7D_%7Bx%5Csim+P_r%7D%5B%5Clog+D%5E%2A%28x%29%5D+%2B+%5Cmathbb%7BE%7D_%7Bx%5Csim+P_g%7D%5B%5Clog%281-D%5E%2A%28x%29%29%5D+%3D+2JS%28P_r+%7C%7C+P_g%29+-+2%5Clog+2)（公式9）

我们可以把KL散度（注意下面是先g后r）变换成含D^*的形式：

![](http://zhihu.com/equation?tex=%5Cbegin%7Balign%7D%0AKL%28P_g+%7C%7C+P_r%29+%26%3D+%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5B%5Clog+%5Cfrac%7BP_g%28x%29%7D%7BP_r%28x%29%7D%5D+%5C%5C%0A%26%3D+%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5B%5Clog+%5Cfrac%7BP_g%28x%29+%2F+%28P_r%28x%29+%2B+P_g%28x%29%29%7D%7BP_r%28x%29+%2F+%28P_r%28x%29+%2B+P_g%28x%29%29%7D%5D+%5C%5C%0A%26%3D+%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5B%5Clog+%5Cfrac%7B1+在这里，我们可以想象一下，gan是一个智能的，他在这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常-+D%5E%2A%28x%29%7D%7BD%5E%2A%28x%29%7D%5D+%5C%5C%0A%26%3D+%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5Clog+%5B1+-+D%5E%2A%28x%29%5D+-++%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5Clog+D%5E%2A%28x%29%0A%5Cend%7Balign%7D+%5C%5C)（公式10）

由公式3，9，10可得最小化目标的等价变形

![](http://zhihu.com/equation?tex=%5Cbegin%7Balign%7D%0A%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5B-%5Clog+D%5E%2A%28x%29%5D+%26%3D++KL%28P_g+%7C%7C+P_r%29+-++%5Cmathbb%7BE%7D_%7Bx+%5Csim+P_g%7D+%5Clog+%5B1+-+D%5E%2A%28x%29%5D+%5C%5C%0A%26%3D+KL%28P_g+%7C%7C+P_r%29+-+2JS%28P_r+%7C%7C+P_g%29+%2B+2%5Clog+2+%2B+%5Cmathbb%7BE%7D_%7Bx%5Csim+P_r%7D%5B%5Clog+D%5E%2A%28x%29%5D%0A%5Cend%7Balign%7D)
注意上式最后两项不依赖于生成器G，最终得到最小化公式3等价于最小化

![](http://zhihu.com/equation?tex=KL%28P_g+%7C%7C+P_r%29+-+2JS%28P_r+%7C%7C+P_g%29)（公式11）

这个等价最小化目标存在两个严重的问题。第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。

第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量，KL(P_g || P_r)与KL(P_r || P_g)是有差别的。以前者为例

* 当![](http://zhihu.com/equation?tex=P_g%28x%29%5Crightarrow+0)而![](http://zhihu.com/equation?tex=P_r%28x%29%5Crightarrow+1)时，![](http://zhihu.com/equation?tex=P_g%28x%29+%5Clog+%5Cfrac%7BP_g%28x%29%7D%7BP_r%28x%29%7D+%5Crightarrow+0)，对KL(P_g || P_r)贡献趋近0
* 当![](http://zhihu.com/equation?tex=P_g%28x%29%5Crightarrow+1)而![](http://zhihu.com/equation?tex=P_r%28x%29%5Crightarrow+0)时，![](http://zhihu.com/equation?tex=P_g%28x%29+%5Clog+%5Cfrac%7BP_g%28x%29%7D%7BP_r%28x%29%7D+%5Crightarrow+%2B%5Cinfty)，对KL(P_g || P_r)贡献趋近正无穷

换言之，KL(P_g || P_r)对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。**在这里，我们可以想象一下，gan是一个智能的，他在这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。**


### WGAN之前的一个过渡解决方案——加噪方案

* 就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。
* 加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！

### 




